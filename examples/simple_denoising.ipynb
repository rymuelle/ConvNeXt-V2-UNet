{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed976820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ConvNeXtUNet.convnextv2_unet import convnextv2unet_atto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three models with predefined sizes are provided \n",
    "model = convnextv2unet_atto( ms_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cbfaf6",
   "metadata": {},
   "source": [
    "Now, lets do a simple image denoising task as a demonstration of the U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46efe38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393b1f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates a synthetic image\n",
    "# We can add noise to this to simulate a noisy image\n",
    "\n",
    "import random\n",
    "def create_random_pixel_image(channels, height, width):\n",
    "    \"\"\"\n",
    "    Generates a 2D tensor (image) of zeros with a single '1' at the center pixel.\n",
    "\n",
    "    Args:\n",
    "    channels: The channels of the image (number of channels).\n",
    "    height: The height of the image (number of rows).\n",
    "    width: The width of the image (number of columns).\n",
    "\n",
    "    Returns:\n",
    "    A torch.Tensor of shape (height, width) with dtype torch.float32.\n",
    "    \"\"\"\n",
    "    if height <= 0 or width <= 0:\n",
    "        raise ValueError(\"Height and width must be positive integers.\")\n",
    "\n",
    "    image = torch.zeros((channels, height, width), dtype=torch.float32)\n",
    "\n",
    "    pixel_height = random.randint(0,height-2)\n",
    "    pixel_width = random.randint(0, width-2)\n",
    "\n",
    "    for channel in range(channels):\n",
    "        image[channel, pixel_height, pixel_width] = 1.0\n",
    "        image[channel, pixel_height+1, pixel_width+1] = 1.0\n",
    "        image[channel, pixel_height, pixel_width+1] = 1.0\n",
    "        image[channel, pixel_height+1, pixel_width] = 1.0\n",
    "\n",
    "    return image.unsqueeze(0)\n",
    "\n",
    "sample_image = create_random_pixel_image(3, 32, 32)\n",
    "plt.imshow(sample_image[0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(image, scale=0.5):\n",
    "    B, C, W, H = image.shape\n",
    "    image += torch.rand(B, C, W, H) * scale\n",
    "    return image\n",
    "\n",
    "noisy_sample = add_noise(sample_image)\n",
    "plt.imshow(noisy_sample[0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16479a",
   "metadata": {},
   "source": [
    "Now, let's train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b631a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('mps')\n",
    "    if torch.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    return torch.device('cpu')\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e804435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These training parameters are not optimizd and are merely meant to quickly demonstrate training.\n",
    "\n",
    "num_epochs = 10\n",
    "num_batches = 500\n",
    "batch_size = 3\n",
    "\n",
    "lr = 2e-4\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, num_epochs)\n",
    "from ConvNeXtUNet.losses.MultiScaleLoss import MultiScaleLoss\n",
    "loss_func = MultiScaleLoss(loss_criterion=torch.nn.MSELoss())\n",
    "\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7852f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss_per_batch = 0\n",
    "    for batch in range(num_batches):\n",
    "        ground_truth = torch.cat([create_random_pixel_image(3, 32, 32) \n",
    "                                for _ in range(batch_size)])\n",
    "        noisy_images = add_noise(ground_truth.clone())\n",
    "        \n",
    "        ground_truth = ground_truth.to(device)\n",
    "        noisy_images = noisy_images.to(device)\n",
    "\n",
    "        pred = model(noisy_images)\n",
    "        loss = loss_func(pred, ground_truth)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss_per_batch += loss\n",
    "    # MSE by default computes the mean, so divide by batches\n",
    "    print(f'Epoch {epoch}: Loss: {total_loss_per_batch/num_batches:.2e} LR: {sched.get_last_lr()[0]:.2e}')\n",
    "    sched.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5016250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_tensor(tensor):\n",
    "    return tensor.detach().cpu().permute(1, 2, 0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "noisy_img = format_tensor(noisy_images[0])\n",
    "plt.imshow(noisy_img)\n",
    "plt.title('Noisy image')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "pred_img = format_tensor(pred[-1][0])\n",
    "plt.imshow(pred_img)\n",
    "plt.title('Denoised image')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "gt_image = format_tensor(ground_truth[0])\n",
    "plt.imshow(gt_image)\n",
    "plt.title('Ground truth')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(noisy_img-pred_img)\n",
    "plt.title('Extracted noise')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb291abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OnSight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
